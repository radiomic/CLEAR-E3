---
title: Item#57
layout: home
parent: Item 50 to Item 58
nav_order: 57

---
## CLEAR item#57

“Sharing final model files. Share the final model files for internal or external testing. Describe how inputs should be prepared to use the model. Also, include the source code that was used for pre-processing the input data. Specify the reason in case the final model data are not available.” [1] (from [the article by Kocak et al.](https://doi.org/10.1186/s13244-023-01415-8); licensed under CC BY 4.0)


### Reporting examples for item#57

> **Example#1.** “The model, its implementation instructions, all required files for data extraction and processing are available in the online study repository ([https://github.com/rcuocolo/mri_act_cs2](https://github.com/rcuocolo/mri_act_cs2)).” [2] (from [the article by Gitto et al.](https://doi.org/10.1016/j.ebiom.2021.103757); licensed under CC BY-NC-ND 4.0)

> **Example#2.** “The exact description of the machine learning methods with the model and training parameters used can be found as code online ([https://github.com/NikonPic/bonetumor-radiomics](https://github.com/NikonPic/bonetumor-radiomics)).” [3] (from [the article by von Schacky et al.](https://doi.org/10.1007/s00330-022-08764-w); licensed under CC BY 4.0)

### Explanation and elaboration of item#57
Item#57 focuses on the importance of sharing the final model and source code to increase the transparency of radiomics research. This is strictly related to the reproducibility concerns of current radiomics research. The limited availability of open-source code and data is one of the main causes of poor validation and clinical translation of radiomics research. Currently, there is a paucity of radiomics and artificial intelligence studies reporting providing the final model code, as reported by recent systematic reviews [4-6]. Most radiomics research is oriented to publishing new models without providing access to the code, rather than testing the performance of already developed data.

### References

{: .fs-2 }
1. 	Kocak B, Baessler B, Bakas S, et al (2023) CheckList for EvaluAtion of Radiomics research (CLEAR): a step-by-step reporting guideline for authors and reviewers endorsed by ESR and EuSoMII. Insights Imaging 14:75. [https://doi.org/10.1186/s13244-023-01415-8](https://doi.org/10.1186/s13244-023-01415-8)
2. 	Gitto S, Cuocolo R, Langevelde K van, et al (2022) MRI radiomics-based machine learning classification of atypical cartilaginous tumour and grade II chondrosarcoma of long bones. eBioMedicine 75:. [https://doi.org/10.1016/j.ebiom.2021.103757](https://doi.org/10.1016/j.ebiom.2021.103757)
3. 	von Schacky CE, Wilhelm NJ, Schäfer VS, et al (2022) Development and evaluation of machine learning models based on X-ray radiomics for the classification and differentiation of malignant and benign bone tumors. Eur Radiol 32:6247–6257. [https://doi.org/10.1007/s00330-022-08764-w](https://doi.org/10.1007/s00330-022-08764-w)
4. 	Ponsiglione A, Stanzione A, Spadarella G, et al (2023) Ovarian imaging radiomics quality score assessment: an EuSoMII radiomics auditing group initiative. Eur Radiol 33:2239–2247. [https://doi.org/10.1007/s00330-022-09180-w](https://doi.org/10.1007/s00330-022-09180-w)
5. 	Cannella R, Vernuccio F, Klontzas ME, et al (2023) Systematic review with radiomics quality score of cholangiocarcinoma: an EuSoMII Radiomics Auditing Group Initiative. Insights Imaging 14:21. [https://doi.org/10.1186/s13244-023-01365-1](https://doi.org/10.1186/s13244-023-01365-1)
6. 	Kocak B, Yardimci AH, Yuzkan S, et al (2023) Transparency in Artificial Intelligence Research: a Systematic Review of Availability Items Related to Open Science in Radiology and Nuclear Medicine. Acad Radiol 30:2254–2266. [https://doi.org/10.1016/j.acra.2022.11.030](https://doi.org/10.1016/j.acra.2022.11.030)


[Back](https://radiomic.github.io/CLEAR-E3/docs/Item12.html){: .btn .btn-purple  .mr-5  }
[Next](https://radiomic.github.io/CLEAR-E3/docs/Item57.html){: .btn .btn-purple   }
